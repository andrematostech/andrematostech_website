export const heroCodeLines = [
  "from typing import List, Dict, Iterable",
  "import time",
  "import json",
  "import os",
  "import random",
  "",
  "class LLMClient:",
  "    def __init__(self, model: str, temperature: float = 0.2):",
  "        self.model = model",
  "        self.temperature = temperature",
  "",
  "    def generate(self, prompt: str) -> str:",
  "        return f\"[{self.model}] {prompt}\"",
  "",
  "def chunk(text: str, n: int) -> List[str]:",
  "    return [text[i:i+n] for i in range(0, len(text), n)]",
  "",
  "def build_prompt(tags: List[str]) -> str:",
  "    return \"// \" + \" | \".join(tags)",
  "",
  "def stream(client: LLMClient, prompt: str) -> Iterable[str]:",
  "    for part in chunk(prompt, 6):",
  "        yield client.generate(part)",
  "        time.sleep(0.01)",
  "",
  "def parse(payload: str) -> Dict[str, str]:",
  "    return json.loads(payload)",
  "",
  "def cache_put(store: Dict[str, str], key: str, value: str):",
  "    store[key] = value",
  "",
  "def cache_get(store: Dict[str, str], key: str, default: str = \"\") -> str:",
  "    return store.get(key, default)",
  "",
  "def retry(fn, n: int = 3, delay_s: float = 0.05):",
  "    for _ in range(n):",
  "        try:",
  "            return fn()",
  "        except Exception:",
  "            time.sleep(delay_s)",
  "    raise RuntimeError(\"failed after retries\")",
  "",
  "def make_tags() -> List[str]:",
  "    base = [\"react\", \"vite\", \"gsap\", \"llm\", \"ai\"]",
  "    random.shuffle(base)",
  "    return base[:4]",
  "",
  "def save_log(path: str, lines: List[str]):",
  "    with open(path, \"w\", encoding=\"utf-8\") as f:",
  "        for line in lines:",
  "            f.write(line + \"\\n\")",
  "",
  "def main():",
  "    client = LLMClient(\"gpt-4.1-mini\", temperature=0.15)",
  "    tags = make_tags()",
  "    prompt = build_prompt(tags)",
  "    cache: Dict[str, str] = {}",
  "    outputs: List[str] = []",
  "    for out in stream(client, prompt):",
  "        outputs.append(out)",
  "        print(out)",
  "    cache_put(cache, \"last\", outputs[-1] if outputs else \"\")",
  "    save_log(os.path.join(\".\", \"out.log\"), outputs)",
  "    _ = cache_get(cache, \"last\")",
  "",
  "def metrics(lines: List[str]) -> Dict[str, int]:",
  "    return {\"lines\": len(lines), \"chars\": sum(len(x) for x in lines)}",
  "",
  "def sample() -> List[str]:",
  "    return [\"foo\", \"bar\", \"baz\", \"qux\"]",
  "",
  "def pipeline() -> List[str]:",
  "    items = sample()",
  "    return [s.upper() for s in items if s]",
  "",
  "def summarize(lines: List[str]) -> str:",
  "    m = metrics(lines)",
  "    return f\"lines={m['lines']} chars={m['chars']}\"",
  "",
  "def report(lines: List[str]):",
  "    print(summarize(lines))",
  "",
  "def run():",
  "    lines = [\"init\", \"load\", \"build\", \"deploy\"]",
  "    report(lines)",
  "",
  "run()",
  "",
  "if __name__ == \"__main__\":",
  "    main()"
];
